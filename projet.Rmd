---
title: "R Notebook"
output: html_notebook
---
# Projet Apprentissage statistque : Classification des postes des joueurs de fotball

## I. Introduction

## Présentation du problème

Il y a 4 types de positionnement au football : Gardien de but, défenseur, milieu et attaquant, comme on peut le voir sur l'image ci-dessous
![Les positions au football](postes_foot.PNG)

Certains jeunes joueurs peuvent jouer à des postes très différents. Notre objectif est de pouvoir conseiller le poste qui conviendrait le mieux à ces jeunes joueurs. Pour cela, nous utiliserons des méthodes de machine learning.

Pour cela, nous avons utilisé le jeu de données de FIFA 21 afin de pouvoir entrainer nos modèles.

```{r}
players=read.csv("FIFA.csv")
```
Sur ce dataset, chaque joueur possède un ID, son nom, sa nationalité, une note globale, son club et des informations sur son contrat (salaire, fin du contrat), ses caractéristiques physiques (poids, taille, corpulance), sa position. Enfin, les 30 dernières colones concernent les qualités footballistiques du joueur tels que sa qualité de passe, sa vitesse, sa capacité à controler le ballon, sa vision du jeu ou ses qualités défensives. Sur chaque caractéristiqur, le joueur est noté sur 100.

Comme nous cherchons à prédire le poste selon les caractéristiques du joueurs, Les colonnes de ce jeu de données qui nous intéressent sont le poste ou "position"(la variable à expliquer) et les colonnes concernant les caractéristiques du joueurs. Nous les sélectionnons ci-dessous.
```{r}
players_2=players[,c("Position","Crossing", "Finishing","Heading.Accuracy","Short.Passing", "Volleys", "Dribbling", "Curve",              "FK.Accuracy","Long.Passing", "Ball.Control", "Acceleration", "Sprint.Speed","Agility","Reactions","Balance","Shot.Power","Jumping",   "Stamina","Strength","Long.Shots", "Aggression", "Interceptions", "Positioning","Vision","Penalties", "Composure",               "Defensive.Awareness", "Standing.Tackle", "Sliding.Tackle")]

players_2=drop_na(players_2)
players_3 = players_2 # Pour la 2e partie
colnames(players_2)
```
## Présentation du dataset

Sur ce dataset, chaque joueur possède un ID, son nom, sa nationalité, une note globale, son club et des informations sur son contrat (salaire, fin du contrat), ses caractéristiques physiques (poids, taille, corpulance), sa position. Enfin, les 30 dernières colones concernent les qualités footballistiques du joueur tels que sa qualité de passe, sa vitesse, sa capacité à controler le ballon, sa vision du jeu ou ses qualités défensives. Sur chaque caractéristiqur, le joueur est noté sur 100.

Comme nous cherchons à prédire le poste selon les caractéristiques du joueurs, Les colonnes de ce jeu de données qui nous intéressent sont le poste ou "position"(la variable à expliquer) et les colonnes concernant les caractéristiques du joueurs. 

Les différentes positions dans Fifa sont expliquées dans l'image ci-dessous
__Mettre l'image avec les postes dans Fifa__
![Les positions dans Fifa](postes_Fifa.PNG)


Classer les gardiens avec les autres joueurs n'a que peu d'intérêt. Ce poste est à part, les gardiens s'entraînent souvent de manière spécifique et ont un rôle très différent des autres joueurs. On écarte donc les gardiens de l'étude ainsi que les colonnes concernant les caractériqtiques spécifiques des autres joueurs.

On peut voir également qu'il y a des milieux défensifs et offensifs.  Les milieux défensifs vont avoir des qualités proches de celles des défenseurs tandis que les milieux offensifs seront plus proches des attaquants. 

Pour vérifier cette information sur nos données, nous allons maintenant visualiser les différences et les points commun entre attaquants, milieux et défenseurs. Pour chaque caractéristique, nous ferons une moyenne des notes par type de joueurs, puis nous comparerons les résultats obtenus.
```{r}
Attack=c("LW", "LF", "RW","RF", "CF", "ST")
Defense=c("RB", "RWB", "LB", "LWB", "CB")

index_attack=which(players_2$Position %in%(Attack))
index_attack
players_2[index_attack, "Position"]=1

index_defense=which(players_2$Position %in%(Defense))
index_defense
players_2[index_defense, "Position"]=0
players_2=players_2[c(index_attack,index_defense),]

Midfielder=c("CAM", "CM", "CDM", "LM", "RM")
index_mid=which(players_3$Position %in%(Midfielder))
index_attack=which(players_3$Position %in%(Attack))
index_defense=which(players_3$Position %in%(Defense))
players_3[index_attack, "Position"]=2
players_3[index_mid, "Position"]=1
players_3[index_defense, "Position"]=0

players_3=players_3[c(index_attack,index_defense,index_mid),]
players_3
```
```{r}
n=29
att=colMeans(players_3[which(players_3[,"Position"]==2),2:length(players_3[1,])])
length(colnames(players_3[,-1]))
mid=colMeans(players_3[which(players_3[,"Position"]==1),2:length(players_3[1,])])
def=colMeans(players_3[which(players_3[,"Position"]==0),2:length(players_3[1,])])

mean=data.frame(defense=def,midfield=mid, attack=att)
best_char=c()
for(i in 1:n){
  best_char=c(best_char, as.numeric(which.max(mean[i,])-1) )
}

# On trace le barplot avec les caractéristiques où les attaquants sont les meilleurs
att_best_att=att[which(best_char==2)]
mid_best_att=mid[which(best_char==2)]
def_best_att=def[which(best_char==2)]
col=colnames(players_3[,-1])[which(best_char==2)]

n1=length(att_best_att)
ggplot(data=data.frame(caracteristique=rep(col,3), moyenne=c(att_best_att,mid_best_att,def_best_att), position=c(rep("Att",n1),rep("Mid",n1), rep("Def",n1))))+geom_col(aes(x=caracteristique,y=moyenne, fill=position), position = "dodge", width=0.5, size=3.5)+coord_flip()+ggtitle("Moyenne des caractéristiques où les attaquants sont les meilleurs \n")
```
Les attaquants sont nettement meilleurs que les autres sur les reprises de volées (volleys), la vitesse de pointe (sprint.speed) la finition (l'efficacité devant le but), le placement (positionning) et pour les penaltiesce qui semble logique puisque leur rôle consiste à amener du danger près du but adverse grâce à la vitesse et à marquer. De plus, ce sont plus souvent les attaquants qui tirent les penalty.

Ils sont en revanche similaire proche des milieux en terme de puissance de frappe, de frappe longue et d'accélération. En effet, les milieux peuvent frappent souvent de loin et se doivent d'être explosif.

Enfin, les trois types de joueurs ont une note de "reaction" assez proche puisque quelque soit le poste, un joueur de football doit réagir rapidement lors d'une situation donnée.

Maintenant nous allons analyser les caractéristiques où les défenseurs sont les meilleurs

```{r}
att_best_mid=att[which(best_char==1)]
mid_best_mid=mid[which(best_char==1)]
def_best_mid=def[which(best_char==1)]
col2=colnames(players_3[,-1])[which(best_char==1)]

n2=length(att_best_mid)
ggplot(data=data.frame(caracteristique=rep(col2,3), moyenne=c(att_best_mid,mid_best_mid,def_best_mid), position=c(rep("Att",n2),rep("Mid",n2), rep("Def",n2))))+geom_col(aes(x=caracteristique,y=moyenne, fill=position), position = "dodge", width=0.5, size=3.5)+coord_flip()+ggtitle("Moyenne des caractéristiques où les milieux sont les meilleurs \n")
```
Les milieux sont au coeur du jeu. Ils font le lien entre l'attauqe et la défense. Ils distribuent le jeu par leurs passes et sont des éléments important du dispositif défensif de l'équipe. Cela explique pourquoi leur vision du jeu, leur capacité de passe courte et longue, leur capacité de centre ("crossing"). Ils sont aussi en moyenne plus souple ("Balance") vu qu'ils doivent réalisé à la fois des gestes défensifs et offensifs très différent.
Leur efficacité sur coup-franc est également plus élevé (Free-Kick accuracy)
Leur facilitée à centrer et à tirer les coup-franc peut être du à une bonne note sur "curve" qui consiste à "enrouler" un ballon, c'est à dire à lui donner un effet pour que le ballon ait une trajectoire courbe.

En revanche, ils sont proches des attaquantq concernant la capacité à dribbler, le contrôle du ballon, l'agilité ou capacité à gérer la pression (composure). En effet, ces 2 postes nécessitent d'être à l'aise avec le ballon et de réaliser des gestes décisifs où la pression peut être grande (penalty, coup-franc).

Maintenant nous allons analyser les caractéristiques où les défenseurs sont les meilleurs.
```{r}
att_best_def=att[which(best_char==0)]
mid_best_def=mid[which(best_char==0)]
def_best_def=def[which(best_char==0)]
col3=colnames(players_3[,-1])[which(best_char==0)]

n3=length(att_best_def)
ggplot(data=data.frame(caracteristique=rep(col3,3), moyenne=c(att_best_def,mid_best_def,def_best_def), position=c(rep("Att",n3),rep("Mid",n3), rep("Def",n3))))+geom_col(aes(x=caracteristique,y=moyenne, fill=position), position = "dodge", width=0.5, size=3.5)+coord_flip()+ggtitle("Moyenne des caractéristiques où les défenseurs sont les meilleurs \n")
```
Bien évidemment les défenseurs ont des meilleurs notes pour les gestes défensifs, c'est à dire les tacles debout ou glissés (standing et sliding tackle), les interceptions, l'agressivité (agression), la vigilance défensive (Defensive Awarness).

Ils sont proches des attaquants pour la force et la précision de la tête. En effet, attaquants et défenseurs sont souvent au duel. De plus, il ya beaucoup de duel aérien entre les attquants et les défenseurs. Enfin, les grands  défenseurs montent sur certains coup-franc et sur les corners pour marquer de la tête.

Enfin, sur nos données défenseurs et attaquants sont proches en terme d'endurance.



Ainsi, nous avons pu remarquer que les milieux sont proches des attquants sur 7 des 29 caractéristiques et proches des défenseurs sur une des caractéristques. En revanche, mis à part sur 2 caractéristques, attaquants et défenseurs semblent former 2 groupes bien distincts.

C'est pourquoi, nous commencerons par tester nos modèles en prenant en compte uniquement les défenseurs et les milieux de terrain. Le dataframe "players_2" servira pour la classification entre attaquants et déefenseurs tandis que le dataframe "players_3" servira pour la classification entre défenseurs, milieux et attaquants.

Séparation en jeu de données test et validation
```{r}
n=length(players_2[,1])
n
len.app=as.integer(3*n/4)
len.app
tirage=sample(seq(1,n),len.app, replace=FALSE)
train=players_2[tirage,]
x_train= as.matrix(train[,2:length(train[1,])])
y_train= as.numeric(train[,1])

test=players_2[-tirage,]

x_test= as.matrix(test[,2:length(test[1,])])
y_test= as.numeric(test[,1])
y_test

```



```{r}
#install.packages("keras")

library(tensorflow)
install_tensorflow(version = "nightly")
library(tensorflow)
```
## Modèles que l'on teste :
```{r}
library(tensorflow)
library(keras)

single_perceptron<-function(x_train, activation='sigmoid'){
    model = keras_model_sequential() 
    model %>% layer_dense(units=1, activation=activation, input_shape=29)
return(model)
}
two_layers<-function(x_train, activation='sigmoid'){
    model = keras_model_sequential() 
    model %>% layer_dense(units=15, activation=activation, input_shape=length(x_train[1,]))
    model %>% layer_dense(units=1, activation="softmax")
return(model)
}
three_layers<-function(x_train, activation='sigmoid'){
    model = keras_model_sequential() 
    model %>% layer_dense(units=30, activation=activation, input_shape=length(x_train[1,]))
    model %>% layer_dense(units=15, activation=activation)
    model %>% layer_dense(units=1, activation="softmax")
return(model)
}
```

```{r}
compile_fit<-function(fun, activation, x=x_train,y=y_train, epochs=30, verbose=0, batch_size=5, validation_split=0.3){
  model=fun(x,activation)
  summary(model)
  model %>% compile(loss="binary_crossentropy",optimizer="adam",metrics='accuracy')
  history=model%>% fit(x=x_train, y=y_train, epochs=epochs,batch_size=batch_size,validation_split=validation_split, verbose=verbose)
  
  return(list(model,history))
}


single1 = compile_fit(single_perceptron, "sigmoid", verbose=2)
single1[[1]] %>% evaluate(x_test,y_test)
plot(single1[[2]])

single2 = compile_fit(single_perceptron, "relu", verbose=2)
single2[[1]] %>% evaluate(x_test,y_test)
plot(single2[[2]])

single3 = compile_fit(single_perceptron, "softmax")
single3[[1]] %>% evaluate(x_test,y_test)
plot(single3[[2]])

```
```{r}
two_layers1 = compile_fit(two_layers, "sigmoid", verbose=2)
two_layers1[[1]] %>% evaluate(x_test,y_test)
plot(two_layers1[[2]])

two_layers2 = compile_fit(single_perceptron, "reLU")
two_layers2[[1]] %>% evaluate(x_test,y_test)
plot(two_layers2[[2]])

two_layers3 = compile_fit(single_perceptron, "softmax")
two_layers3[[1]] %>% evaluate(x_test,y_test)
plot(two_layers3[[2]])
```


```{r}
three_layers1 =
```

## Prise en compte des milieux de terrain

```{r}
#Séparation du jeu de données
n=length(players_3[,1])
set.seed(1234)
len.app=as.integer(3*n/4)
tirage=sample(seq(1,n),len.app, replace=FALSE)
train_mid = players_3[tirage,]
x_train_mid = as.matrix(train_mid[,2:length(train[1,])])
y_train_mid = as.numeric(train_mid[,1])

test_mid = players_3[-tirage,]

x_test_mid = as.matrix(test_mid[,2:length(test_mid[1,])])
y_test_mid = as.numeric(test_mid[,1])
```

```{r}
single1_mid = compile_fit(single_perceptron, "relu", x=x_train_mid, y=y_train_mid, loss="sparse_categorical_crossentropy",epochs=30,final_units=3)
single1_mid[[1]] %>% evaluate(x_test_mid,y_test_mid)
plot(single1_mid[[2]])
```
```{r}
single1_mid2 = compile_fit(single_perceptron, "sigmoid", x=x_train_mid, y=y_train_mid, loss="sparse_categorical_crossentropy",final_units=3)
single1_mid2[[1]] %>% evaluate(x_test_mid,y_test_mid)
plot(single1_mid2[[2]])
```
```{r}
single_mid3 = compile_fit(single_perceptron, "softmax", x=x_train_mid, y=y_train_mid, loss="sparse_categorical_crossentropy",final_units=3)
single_mid3[[1]] %>% evaluate(x_test_mid,y_test_mid)
plot(single_mid3[[2]])
```
```{r}
two_mid1 = compile_fit(two_layers, "softmax", x=x_train_mid, y=y_train_mid, loss="sparse_categorical_crossentropy",final_units=3)
two_mid1[[1]] %>% evaluate(x_test_mid,y_test_mid)
plot(two_mid1[[2]])
```
```{r}
two_mid2 = compile_fit(two_layers, "relu", x=x_train_mid, y=y_train_mid, loss="sparse_categorical_crossentropy",final_units=3)
two_mid2[[1]] %>% evaluate(x_test_mid,y_test_mid)
plot(two_mid2[[2]])
```
```{r}
two_mid3 = compile_fit(two_layers, "sigmoid", x=x_train_mid, y=y_train_mid, loss="sparse_categorical_crossentropy",epochs=50,final_units=3)
two_mid3[[1]] %>% evaluate(x_test_mid,y_test_mid)
plot(two_mid3[[2]])
```
```{r}
three_mid1 = compile_fit(three_layers, "softmax", x=x_train_mid, y=y_train_mid, loss="sparse_categorical_crossentropy",final_units=3)
three_mid1[[1]] %>% evaluate(x_test_mid,y_test_mid)
plot(three_mid1[[2]])
```
```{r}
three_mid2 = compile_fit(three_layers, "sigmoid", x=x_train_mid, y=y_train_mid, loss="sparse_categorical_crossentropy",final_units=3)
three_mid2[[1]] %>% evaluate(x_test_mid,y_test_mid)
plot(three_mid2[[2]])
```
```{r}
three_mid3 = compile_fit(three_layers, "relu", x=x_train_mid, y=y_train_mid, loss="sparse_categorical_crossentropy",final_units=3)
three_mid3[[1]] %>% evaluate(x_test_mid,y_test_mid)
plot(three_mid3[[2]])
```
```{r}
model = keras_model_sequential() 
model %>% layer_dense(units=50, activation="sigmoid", input_shape=length(x_train[1,])) 
model %>% layer_dense(units=25, activation="sigmoid") 
model %>% layer_dense(units=12, activation="relu") 
model %>% layer_dense(units=3, activation="softmax")
```
```{r}
model %>% compile(loss="sparse_categorical_crossentropy",optimizer="adam",metrics='accuracy')
summary(model)
history=model%>% fit(x=x_train_mid, y=y_train_mid, epochs=50, batch_size=5,validation_split=0.2)
plot(history)
```

```{r}
model = keras_model_sequential() 
model %>% layer_dense(units=50, activation="sigmoid", input_shape=length(x_train[1,])) 
model %>% layer_dense(units=25, activation="sigmoid") 
model %>% layer_dense(units=12, activation="sigmoid") 
model %>% layer_dense(units=3, activation="softmax")
model %>% compile(loss="sparse_categorical_crossentropy",optimizer="adam",metrics='accuracy')
summary(model)
history=model%>% fit(x=x_train_mid, y=y_train_mid, epochs=50, batch_size=5,validation_split=0.2)
plot(history)
model %>% evaluate(x_test_mid, y_test_mid)
```
```{r}
model = keras_model_sequential() 
model %>% layer_dense(units=50, activation="sigmoid", input_shape=length(x_train[1,])) 
model %>% layer_dense(units=25, activation="softmax") 
model %>% layer_dense(units=12, activation="sigmoid") 
model %>% layer_dense(units=3, activation="softmax")
model %>% compile(loss="sparse_categorical_crossentropy",optimizer="adam",metrics='accuracy')
summary(model)
history=model%>% fit(x=x_train_mid, y=y_train_mid, epochs=50, batch_size=5,validation_split=0.2)
plot(history)
model %>% evaluate(x_test_mid, y_test_mid)
```
```{r}
model = keras_model_sequential() 
model %>% layer_dense(units=50, activation="sigmoid", input_shape=length(x_train[1,])) 
model %>% layer_dense(units=25, activation="relu") 
model %>% layer_dense(units=12, activation="sigmoid") 
model %>% layer_dense(units=3, activation="softmax")
model %>% compile(loss="sparse_categorical_crossentropy",optimizer="adam",metrics='accuracy')
summary(model)
history=model%>% fit(x=x_train_mid, y=y_train_mid, epochs=50, batch_size=5,validation_split=0.2)
plot(history)
model %>% evaluate(x_test_mid, y_test_mid)
```


```{r}
model = keras_model_sequential() 
model %>% layer_dense(units=50, activation="sigmoid", input_shape=length(x_train[1,])) 
model %>% layer_dense(units=25, activation="sigmoid") 
model %>% layer_dense(units=12, activation="sigmoid") 
model %>% layer_dense(units=3, activation="sigmoid")
model %>% compile(loss="sparse_categorical_crossentropy",optimizer="adam",metrics='accuracy')
summary(model)
history=model%>% fit(x=x_train_mid, y=y_train_mid, epochs=50, batch_size=5,validation_split=0.2)
plot(history)
model %>% evaluate(x_test_mid, y_test_mid)
```

```{r}
model = keras_model_sequential() 
model %>% layer_dense(units=50, activation="sigmoid", input_shape=length(x_train[1,])) 
model %>% layer_dense(units=25, activation="relu") 
model %>% layer_dense(units=12, activation="sigmoid") 
model %>% layer_dense(units=3, activation="softmax")
model %>% compile(loss="sparse_categorical_crossentropy",optimizer="adam",metrics='accuracy')
summary(model)
history=model%>% fit(x=x_train_mid, y=y_train_mid, epochs=50, batch_size=5,validation_split=0.2)
plot(history)
model %>% evaluate(x_test_mid, y_test_mid)
```

```{r}
model = keras_model_sequential() 
model %>% layer_dense(units=100, activation="sigmoid", input_shape=length(x_train[1,])) 
model %>% layer_dense(units=50, activation="sigmoid") 
model %>% layer_dense(units=25, activation="sigmoid") 
model %>% layer_dense(units=12, activation="sigmoid")
model %>% layer_dense(units=3, activation="softmax")
model %>% compile(loss="sparse_categorical_crossentropy",optimizer="adam",metrics='accuracy')
summary(model)
history=model%>% fit(x=x_train_mid, y=y_train_mid, epochs=50, batch_size=5,validation_split=0.3)
plot(history)
model %>% evaluate(x_test_mid, y_test_mid)
```

```{r}
model = keras_model_sequential() 
model %>% layer_dense(units=200, activation="sigmoid", input_shape=length(x_train[1,])) 
model %>% layer_dense(units=100, activation="relu") 
model %>% layer_dense(units=50, activation="sigmoid") 
model %>% layer_dense(units=25, activation="relu")
model %>% layer_dense(units=12, activation="sigmoid")
model %>% layer_dense(units=3, activation="softmax")
model %>% compile(loss="sparse_categorical_crossentropy",optimizer="adam",metrics='accuracy')
summary(model)
history=model%>% fit(x=x_train_mid, y=y_train_mid, epochs=50, batch_size=5,validation_split=0.3)
plot(history)
model %>% evaluate(x_test_mid, y_test_mid)
```

```{r}
model = keras_model_sequential() 
model %>% layer_dense(units=200, activation="sigmoid", input_shape=length(x_train[1,])) 
model %>% layer_dense(units=100, activation="relu") 
model %>% layer_dense(units=50, activation="sigmoid") 
model %>% layer_dense(units=25, activation="relu")
model %>% layer_dense(units=12, activation="sigmoid")
model %>% layer_dense(units=3, activation="sigmoid")
model %>% compile(loss="sparse_categorical_crossentropy",optimizer="adam",metrics='accuracy')
summary(model)
history=model%>% fit(x=x_train_mid, y=y_train_mid, epochs=50, batch_size=5,validation_split=0.3)
plot(history)
model %>% evaluate(x_test_mid, y_test_mid)
```

```{r}
model = keras_model_sequential() 
model %>% layer_dense(units=800, activation="sigmoid", input_shape=length(x_train[1,])) 
model %>% layer_dense(units=400, activation="relu") 
model %>% layer_dense(units=200, activation="sigmoid")
model %>% layer_dense(units=100, activation="relu") 
model %>% layer_dense(units=50, activation="sigmoid") 
model %>% layer_dense(units=12, activation="sigmoid")
model %>% layer_dense(units=3, activation="softmax")
model %>% compile(loss="sparse_categorical_crossentropy",optimizer="adam",metrics='accuracy')
summary(model)
history=model%>% fit(x=x_train_mid, y=y_train_mid, epochs=50, batch_size=5,validation_split=0.3)
plot(history)
model %>% evaluate(x_test_mid, y_test_mid)
```

## SVM

On considère prmièrement les données sont non-séparables

```{r}
library(e1071)
```


```{r}
svm_player <- train
svm_player$Position <- as.factor(svm_player$Position)
#mod.svm.lin = svm(Position~.,data=svm_player,kernel="linear",cost=1)
#plot(mod.svm.lin,data = svm_player, Crossing~Finishing)
#plot(mod.svm.lin,data = svm_player, Crossing~Dribbling)
#plot(mod.svm.lin,data = svm_player, Crossing~Volleys)
```

```{r}
library(caret)
library(kernlab)
```

```{r}
svm_player_omit <- na.omit(svm_player)
```

```{r}
C <- c(0.001,0.01,1,10,100,1000)
gr.lin <- expand.grid(C=C)
ctrl <- trainControl(method="cv")
train.mod.lin <- train(Position~.,data=svm_player_omit,method="svmLinear",trControl=ctrl,tuneGrid=gr.lin)
```

```{r}
train.mod.lin
```

```{r}
plot(train.mod.lin, metric = "Accuracy",xTrans=log10,main = "linear svm with criterion accuracy")
plot(train.mod.lin, metric = "Kappa",xTrans=log10,main = "linear svm with criterion kappa")
```



```{r}
#mod.svm.rad <- svm(Position~.,data=svm_player,kernel="radial",gamma=1,cost=1)
#plot(mod.svm.rad,data = svm_player, Crossing~Finishing)
```

**remark**

storing the kernel matrix requires memory that scales quadratically with the number of data points. Training time for traditional SVM algorithms also scales superlinearly with the number of data points. So, svm method is not really feasible for large data sets


```{r}
C <- c(0.001,0.01,1,10,100,1000)
sigma <- c(0.1,0.5,1,2,3,4)
gr <- expand.grid(C=C,sigma=sigma)
ctrl <- trainControl(method="cv")
train.mod.rad <- train(Position~.,data=svm_player_omit,method="svmRadial",trControl=ctrl,tuneGrid=gr)
```

it has to notice that the running time of the radial method is much longer than the basic linear svm method

```{r}
train.mod.rad
```

```{r}
plot(train.mod.rad, metric = "Accuracy",xTrans=log10,main = "radial svm with criterion accuracy")
plot(train.mod.rad, metric = "Kappa",xTrans=log10,main = "radial svm with criterion kappa")
```

But we have risk that the R session be explosed, than we try to find a more classical way to apply the traing process.

```{r}
#tune.out <- tune(svm,Position~.,data=svm_player,kernel="radial",ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4)))
summary(tune.out)
```

(gamma = 1/sigma)

else we use linear svm, it is precise enough

```{r}
tune.out <- tune(svm,Position~.,data=svm_player,kernel="linear",ranges=list(cost=c(0.1,1,10,100,1000)))
summary(tune.out)
```


```{r}
test$Position <- as.factor(test$Position)
test1 = na.omit(test)
prev <- predict(tune.out$best.model,newdata=test1)
confusionMatrix(data = prev, reference = test1$Position)
```

```{r}
mod.final <- svm(Position~.,data=svm_player_omit,kernel="linear",cost=0.1,decision.values=TRUE,probability=TRUE)
prob <- predict(mod.final,newdata=test1,probability=TRUE,decision.values=TRUE)
prob1 <- attr(prob,"probabilities")
```

now we r going to compare with the decision tree:

```{r}
library(rpart)

tree_train_data <- svm_player_omit
tree_test_data <- test1
set.seed(56)
arbre <- rpart(Position~.,data=tree_train_data,cp=0.0001,minsplit=2,minbucket=1)
printcp(arbre)
```


```{r}
cp_opt <- arbre$cptable[which.min(arbre$cptable[,"xerror"]),"CP"]
arbre1 <- prune(arbre,cp=cp_opt)

prev1 <- predict(arbre1,newdata=tree_test_data,type="class")
table(true=tree_test_data$Position,pred=prev1)
```


```{r}
gr = expand.grid(cp=c(10^-(5:0)))
ctrl <- trainControl(method="cv")
train.mod.tree = train(Position ~ ., 
                data = tree_train_data, 
                method = "rpart", 
                trControl = ctrl,
                tuneGrid = gr)
```

```{r}
train.mod.tree
```

```{r}
plot(train.mod.tree, metric = "Accuracy", xTrans = log10, xlab = "log10 Cp", main = "Binary tree (Accuracy criterion)")
plot(train.mod.tree, metric = "Kappa", xTrans = log10, xlab = "log10 Cp", main = "Binary tree (Kappa criterion)")
```

```{r}
library(rpart.plot)
prp(train.mod.tree$finalModel, main = "Best binary tree")
```


we gonna plot the two ROC curves and compare the accuracy.

```{r}
library(plotROC)
```

```{r}
Y1 <- as.numeric(test1$Position)-1
score <- data.frame(svm=prob1[,2],arbre=predict(arbre1,newdata=test1)[,2],Y=Y1)
df <- gather(score,key="Method",value=score,-Y)
ggplot(df)+aes(d=Y,m=score,color=Method)+geom_roc()+theme_classic()
```

apparantly there is no big difference between two models bny comparing the accuracy. Just it has to notice that using decision tree is much faster than svm. 

why decision tree is not computaitionally expensive?

"
Decision trees algorithms do not compute all possible trees when they fit a tree. If they did they would be solving an NP-hard problem. Decision tree fitting algorithms typically make greedy decisions in the fitting process—at each stage they optimize the sub-problem for finding an optimal split with the data in the given node and the keep moving forward in the fitting process. Also, as you move deeper into the decision tree you have a smaller set of data that has made it to the given node so that you will be optimizing the splitting rule over a smaller subset of data. All of these choices are linear scans of the data in the given node. This is not complicated to do but can become somewhat expensive computationally if you have a large number of observations or a large number of covariates to split on. However, a lot of the work can be split up and sent off to different machines to work on so there are ways to build out your computational architecture to scale up. In general though, the method works fairly quickly on lots of the datasets you see in coursework and in many real world scenarios as well."

## ada boost

```{r}
boost.train.data = na.omit(tree_train_data)
boost.test.data = na.omit(tree_test_data)
gr.ada = expand.grid(nIter=c(1,10,20,30,40,50),method=c("Real adaboost"))
mod.ada = train(Position~ ., 
                data = boost.train.data, 
                method = "adaboost", 
                trControl = ctrl, 
                tuneGrid = gr.ada)
```

```{r}
plot(mod.ada, metric = "Accuracy", xlab = "M", main = "Adaboost (Accuracy)")
plot(mod.ada, metric = "Kappa", xlab = "M", main = "Adaboost (Kappa)")
```

```{r}
pred.ada <- predict(mod.ada,boost.test.data)
confusionMatrix(pred.ada,reference = boost.test.data$Position)
```


## Prise en compte des milieux de terrain

```{r}
players_2=players[,c("Position","Crossing", "Finishing","Heading.Accuracy","Short.Passing", "Volleys", "Dribbling", "Curve",              "FK.Accuracy","Long.Passing", "Ball.Control", "Acceleration", "Sprint.Speed","Agility","Reactions","Balance","Shot.Power","Jumping",   "Stamina","Strength","Long.Shots", "Aggression", "Interceptions", "Positioning","Vision","Penalties", "Composure",               "Defensive.Awareness", "Standing.Tackle", "Sliding.Tackle")]

Attack=c("LW", "LF", "RW","RF", "CF", "ST", "CAM")
Defense=c("RB", "RWB", "LB", "LWB", "CB")
Midfielder=c("CAM", "CM", "CDM", "LM", "RM")

index_attack=which(players_2$Position %in%(Attack))
index_defense=which(players_2$Position %in%(Defense))
index_mid=which(players_2$Position %in%(Midfielder))

players_3 <- players_2

players_3[index_attack,"Position"]="A"
players_3[index_defense, "Position"]="D"
players_3[index_mid, "Position"]="M"

players_3=players_3[c(index_attack,index_defense,index_mid),]

players_3 <- na.omit(players_3)
players_3$Position <- as.factor(players_3$Position)

set.seed(1234)
n=length(players_3[,1])
len.app=as.integer(3*n/4)
tirage=sample(seq(1,n),len.app, replace=FALSE)
train=players_3[tirage,]
x_train= train[,2:length(train[1,])]
y_train= train[,1]
test=players_3[-tirage,]
x_test= test[,2:length(test[1,])]
y_test= test[,1]
```

```{r}
str(players_3)
```

### SVM

```{r}
library(e1071)
```

```{r}
#model <- svm(Position~.,data=train,kernel="radial",gamma=1,cost=1)
```

```{r}
#tune.3positions.lin <- tune(svm,Position~.,data=train,kernel="linear",ranges=list(cost=c(0.01,0.1,1,10,100,1000)))
#summary(tune.3positions.lin)
```

```{r}
#tune.3positions.rad <- tune(svm,Position~.,data=train,kernel="radial",ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4)))
#summary(tune.3positions.rad)
```

```{r}
#prev <- predict(tune.3positions.rad$best.model,newdata=test)
#confusionMatrix(data = prev, reference = test$Position)
```

```{r}
#final.model <- svm(Position~.,data=train,kernel="radial",gamma=0.5,cost=10,decision.values=TRUE,probability=TRUE)
#prob <- predict(final.model,newdata=test,probability=TRUE,decision.values=TRUE)
#prob1 <- attr(prob,"probabilities")
```

```{r}
gr.svm.poly = expand.grid(C=c(0.0001,0.001,0.01,0.1,1), degree=c(2,3,4,5), scale=c(1))
train.svm.poly = train(Position~., 
                     data = train, 
                     method = "svmPoly", 
                     trControl = ctrl, 
                     tuneGrid = gr.svm.poly)
```

```{r}
train.svm.poly
```


```{r}
plot(train.svm.poly, metric = "Accuracy", xTrans = log10, xlab = "log10 Cp", main = "Polynomial svm (Accuracy criterion)")
plot(train.svm.poly, metric = "Kappa", xTrans = log10, xlab = "log10 Cp", main = "Polynomial svm (Kappa criterion)")
```

```{r}
train.svm.poly$finalModel
```


```{r}
pred.svm.poly <- predict(train.svm.poly,newdata = test)
```
