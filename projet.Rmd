---
title: "R Notebook"
output: html_notebook
---

# Projet Apprentissage statistque : Classification des postes des joueurs de fotball

## I. Introduction

Le but de ce projet est de classer le poste des joueurs de football issue du dataset FIFA 2021.

```{r}
players=read.csv("FIFA.csv")
head(players)
```

Sur ce dataset, chaque joueur possède un ID, son nom, sa nationalité, une note globale, son club et des informations sur son contrat (salaire, fin du contrat), ses caractéristiques physiques (poids, taille, corpulance), sa position. Enfin, les 30 dernières colones concernent les qualités footballistiques du joueur tels que sa qualité de passe, sa vitesse, sa capacité à controler le ballon, sa vision du jeu ou ses qualités défensives. Sur chaque caractéristique, le joueur est noté sur 100.

Comme nous cherchons à prédire le poste selon les caractéristiques du joueurs, Les colonnes de ce jeu de données qui nous intéressent sont le poste ou "position" (la variable à expliquer) et les colonnes concernant les caractéristiques du joueurs. 

![Les positions au football](postes_foot.PNG)

Il y a 4 types de positionnement au football : Gardien de but, défenseur, milieu et attaquant.
Classer les gardiens avec les autres joueurs n'a que peu d'intérêt. Ce poste est à part, les gardiens s'entraînent souvent de manière spécifique et ont un rôle très différent des autres joueurs. On écarte donc les gardiens de l'étude ainsi que les colonnes concernant les caractériqtiques spécifiques des autres joueurs.

On peut voir également qu'il y a des milieux défensifs et offensifs.  Les milieux défensifs vont avoir des qualités proches de celles des défenseurs tandis que les milieux offensifs seront plus proches des attaquants. 
Ainsi, afin d'éviter que nos modèles ne soient faussés par cette spécificités du football, nous supprimerons les milieux de l'étude et chercherons simplement à classer les joueurs entre "attaquant" et "défenseur"

```{r}
players_2=players[,c("Position","Crossing", "Finishing","Heading.Accuracy","Short.Passing", "Volleys", "Dribbling", "Curve", "FK.Accuracy","Long.Passing", "Ball.Control", "Acceleration", "Sprint.Speed","Agility","Reactions","Balance","Shot.Power","Jumping", "Stamina","Strength","Long.Shots", "Aggression", "Interceptions", "Positioning","Vision","Penalties", "Composure","Defensive.Awareness", "Standing.Tackle", "Sliding.Tackle")]
colnames(players_2)
```

```{r}
players_2
```

```{r}
Attack=c("LW", "LF", "RW","RF", "CF", "ST", "CAM")
Defense=c("RB", "RWB", "LB", "LWB", "CB")
index_attack=which(players_2$Position %in%(Attack))
index_attack
players_2[index_attack, "Position"]=1
players_2

index_defense=which(players_2$Position %in%(Defense))
index_defense
players_2[index_defense, "Position"]=0
players_2=players_2[c(index_attack,index_defense),]
players_2
```

```{r}
#Suppression des Na
  library(tidyverse)
drop_na(players_2)
```

Séparation en jeu de données test et validation
```{r}
n=length(players_2[,1])
n
len.app=as.integer(3*n/4)
len.app
tirage=sample(seq(1,n),len.app, replace=FALSE)
train=players_2[tirage,]
x_train= as.matrix(train[,2:length(train[1,])])
y_train= as.numeric(train[,1])

test=players_2[-tirage,]

x_test= as.matrix(test[,2:length(test[1,])])
y_test= as.numeric(test[,1])
y_test

```



```{r}
#install.packages("keras")

library(tensorflow)
install_tensorflow(version = "nightly")
library(tensorflow)
```

## Modèles que l'on teste :

```{r}
library(tensorflow)
library(keras)

single_perceptron<-function(x_train, activation='sigmoid'){
    model = keras_model_sequential() 
    model %>% layer_dense(units=1, activation=activation, input_shape=29)
return(model)
}
two_layers<-function(x_train, activation='sigmoid'){
    model = keras_model_sequential() 
    model %>% layer_dense(units=15, activation=activation, input_shape=length(x_train[1,]))
    model %>% layer_dense(units=1, activation="softmax")
return(model)
}
three_layers<-function(x_train, activation='sigmoid'){
    model = keras_model_sequential() 
    model %>% layer_dense(units=30, activation=activation, input_shape=length(x_train[1,]))
    model %>% layer_dense(units=15, activation=activation)
    model %>% layer_dense(units=1, activation="softmax")
return(model)
}
```

```{r}
compile_fit<-function(fun, activation, x=x_train,y=y_train, epochs=30, verbose=0, batch_size=5, validation_split=0.3){
  model=fun(x,activation)
  summary(model)
  model %>% compile(loss="binary_crossentropy",optimizer="adam",metrics='accuracy')
  history=model%>% fit(x=x_train, y=y_train, epochs=epochs,batch_size=batch_size,validation_split=validation_split, verbose=verbose)
  
  return(list(model,history))
}


single1 = compile_fit(single_perceptron, "sigmoid", verbose=2)
single1[[1]] %>% evaluate(x_test,y_test)
plot(single1[[2]])

single2 = compile_fit(single_perceptron, "relu", verbose=2)
single2[[1]] %>% evaluate(x_test,y_test)
plot(single2[[2]])

single3 = compile_fit(single_perceptron, "softmax")
single3[[1]] %>% evaluate(x_test,y_test)
plot(single3[[2]])

```

```{r}
two_layers1 = compile_fit(two_layers, "sigmoid", verbose=2)
two_layers1[[1]] %>% evaluate(x_test,y_test)
plot(two_layers1[[2]])

two_layers2 = compile_fit(single_perceptron, "reLU")
two_layers2[[1]] %>% evaluate(x_test,y_test)
plot(two_layers2[[2]])

two_layers3 = compile_fit(single_perceptron, "softmax")
two_layers3[[1]] %>% evaluate(x_test,y_test)
plot(two_layers3[[2]])
```





```{r message=FALSE, warning=FALSE}
library(kernlab)
data(spam)
spamX <- as.matrix(spam[,-58])
#spamY <- to_categorical(as.numeric(spam$type)-1, 2)
spamY <- as.numeric(spam$type)-1
```



```{r}
set.seed(5678)
perm <- sample(4601,3000)
appX <- spamX[perm,]
appX
appY <- spamY[perm]
validX <- spamX[-perm,]
validY <- spamY[-perm]
```

1. Using train data, train a simple perceptron with an activation function  **sigmoïde**. We use 30 epochs and  batchs of size 5.


We define first the structure of the nework, 1 layer with 1 neuron :
```{r}
percep.sig <- keras_model_sequential() 
percep.sig %>% layer_dense(units=1,input_shape = 57,activation="sigmoid")
```

```{r}
summary(percep.sig)
```

We choose then the loss function, the optimisation algorithm and a  critèrium to measure the performance:

```{r}
percep.sig %>% compile(
  loss="binary_crossentropy",
  optimizer="adam",
  metrics="accuracy"
)
```

We then **fit** the parameters (batchs size, epochs number...)

```{r message=FALSE, warning=FALSE}
p.sig <- percep.sig %>% fit(
  x=appX,
  y=appY,
  epochs=30,
  batch_size=5,
  validation_split=0.2,
  verbose=2
)
p.sig
```

The function **plot** helps to visualize la perte et pa performance en fonction du nombre d'epochs :

```{r}
plot(p.sig)
```

# Régression logistique

```{r}
train$Position = as.factor(train$Position)
```

```{r}
temp = is.na(apply(train[,2:length(colnames(train))],1,sum))
nRemovedTrain = sum(1*temp)
train2 = train[!temp,]
summary(train2)
```


```{r}
temp = is.na(apply(test[,2:length(colnames(test))],1,sum))
nRemovedTest = sum(1*temp)
test2 = test[!temp,]
summary(test2)
```


```{r}
modeleRegLog = glm(Position ~ ., data = train2, family = binomial)
summary(modeleRegLog)
```


```{r}
modeleRegLogCorr = step(modeleRegLog, direction = "both", k = log(n))
```

```{r}
summary(modeleRegLogCorr)
residus = modeleRegLogCorr$residuals
fittedValuesTrain = round(modeleRegLogCorr$fitted.values)
results = summary(as.factor((as.double(train2$Position)-1-round(modeleRegLogCorr$fitted.values))^2))
resultats = results[1]/(sum(results))*100
resultats
#fittedValuesTrain
```

```{r}
prediction = round(predict.glm(modeleRegLogCorr, newdata = test2, type = "response"))
resultsTest = summary(as.factor((as.double(test2$Position)-prediction)^2))
tauxErreur = resultsTest[1]/(sum(resultsTest))*100
resultsTest
tauxErreur
```

## Prise en compte des milieux de terrain

```{r}
Midfielder=c("CAM", "CM", "CDM", "LM", "RM")
Attack=c("LW", "LF", "RW","RF", "CF", "ST")
Defense=c("RB", "RWB", "LB", "LWB", "CB")
index_mid=which(players$Position %in%(Midfielder))

players_3=players[,c("Position","Crossing", "Finishing","Heading.Accuracy","Short.Passing", "Volleys", "Dribbling", "Curve", "FK.Accuracy","Long.Passing", "Ball.Control", "Acceleration", "Sprint.Speed","Agility","Reactions","Balance","Shot.Power","Jumping", "Stamina","Strength","Long.Shots", "Aggression", "Interceptions", "Positioning","Vision","Penalties", "Composure","Defensive.Awareness", "Standing.Tackle", "Sliding.Tackle")]

players_3[index_mid, "Position"]=1

players_3[index_defense, "Position"]=0

players_3[index_attack, "Position"]=2

players_3=players_3[c(index_attack,index_defense,index_mid),]
players_3$Position = as.factor(players_3$Position)

temp = is.na(apply(players_3[,2:length(colnames(train))],1,sum))
nRemovedTrain = sum(1*temp)
players_3 = players_3[!temp,]
summary(players_3)
```

Création de l'ensemble défense et de l'ensemble attaque

```{r}
players_3_def = players_3
players_3_def$Position[which(players_3_def$Position=='2')] = '1'
players_3_def$Position = as.integer(players_3_def$Position)
players_3_def$Position = as.factor(players_3_def$Position)
summary(players_3_def$Position)

players_3_att = players_3
players_3_att$Position[which(players_3_att$Position=='1')] = '0'
players_3_att$Position[which(players_3_att$Position=='2')] = '1'
players_3_att$Position = as.integer(players_3_att$Position)
players_3_att$Position = as.factor(players_3_att$Position)
summary(players_3_att$Position)
summary(players_3$Position)
```



Création des ensemble d'entraînement et de test pour def

```{r}
n=length(players_3_def[,1])
n
len.app=as.integer(3*n/4)
len.app
tirage=sample(seq(1,n),len.app, replace=FALSE)
train_def=players_3_def[tirage,]
x_train_def= as.matrix(train_def[,2:length(train_def[1,])])
y_train_def= train_def$Position

test_def=players_3_def[-tirage,]

x_test_def= as.matrix(test_def[,2:length(test_def[1,])])
y_test_def= (test_def[,1])
```

Création des ensemble d'entraînement et de test pour att

```{r}
train_att=players_3_att[tirage,]
x_train_att= as.matrix(train_att[,2:length(train_att[1,])])
y_train_att= train_att$Position

test_att=players_3_att[-tirage,]

x_test_att= as.matrix(test_att[,2:length(test_att[1,])])
y_test_att= (test_att[,1])
```


Création du modèle pour def :

```{r}
mod_def = glm(Position ~ ., data = train_def, family = binomial)
summary(mod_def)
```

```{r include=FALSE}
mod_def = step(mod_def, direction = "both", k = log(n))
```


```{r}
summary(mod_def)
```

Vérification des performances :

```{r}
pred_def = predict.glm(mod_def, newdata = test_def, type = "response")
pred_def = round(pred_def)

ratio = summary(as.factor((pred_def - (as.integer(y_test_def)-1))^2))
ratio = ratio[1]/(sum(ratio))

pred_def = as.factor(pred_def)
summary(pred_def)
summary(y_test_def)
ratio
```
Création du modèle pour att :

```{r}
mod_att = glm(Position ~ ., data = train_att, family = binomial)
summary(mod_att)
```

```{r include=FALSE}
mod_att = step(mod_att, direction = "both", k = log(n))
```


```{r}
summary(mod_att)
```

Vérification des performances :

```{r}
pred_att = predict.glm(mod_att, newdata = test_att, type = "response")
pred_att = round(pred_att)

ratio2 = summary(as.factor((pred_att - (as.integer(y_test_att)-1))^2))
ratio2 = ratio2[1]/(sum(ratio2))

pred_att = as.factor(pred_att)
summary(pred_att)
summary(y_test_att)
ratio2
```

Assemblage des prédictions pour reconstruire la prédiction finale incluant défenseur, attanquant, et milieu de terrain :

```{r}
pred_def = as.matrix(pred_def)
pred_att = as.matrix(pred_att)
tempo = cbind(pred_att, pred_def)
pred_finale = as.integer(pred_def)-1
summary(as.factor(pred_finale))
pred_finale[which(pred_def=='1' && pred_att=='1')] = 2
summary(as.factor(pred_finale))
pred_finale[which((pred_def=='1' && pred_att=='2') || pred_def=='2' && pred_att=='1')] = 1
summary(as.factor(pred_finale))
pred_finale = as.factor(pred_finale)
```


```{r}
summary(pred_finale)
```





```{r}
train3 = train2[-index_defense,]
summary(train3$Position)
summary(train2$Position)
mod4 = glm(Position ~ ., data = train3, family = binomial)
summary(modeleRegLog)
```

```{r include=FALSE}
mod4 = step(mod4, direction = "both", k = log(n))
```

```{r}
summary(mod4)
```


```{r}
pred = predict.glm(mod3, newdata = train2, type = "response")
pred = as.factor(round(pred))
predFin = pred
summary(pred)
summary(train2$Position)
```

```{r}
pred = predict.glm(mod4, newdata = train3, type = "response")
pred = as.factor(round(pred))
summary(pred)
summary(train3$Position)
```

```{r}
modTest = vglm(Position~.,data = train, family = multinomial)
summary(modTest)
```

Sélection de variables :

```{r}
predict.vgam(modTest, newdata = test, type = 'response')
```

```{r}
n=length(players_3[,1])
n
len.app=as.integer(3*n/4)
len.app
tirage=sample(seq(1,n),len.app, replace=FALSE)
train=players_3[tirage,]
x_train= as.matrix(train[,2:length(train[1,])])
y_train= train$Position

test=players_3[-tirage,]

x_test= as.matrix(test[,2:length(test[1,])])
y_test= (test[,1])
```

```{r}
modTest = vglm(Position~.,data = train, family = multinomial)
summary(modTest)
```

```{r}
prediction = predictvglm(modTest, newdata = test, type = 'response')
```


```{r}
plot(prediction[,1])
plot(prediction[,2])
plot(prediction[,3])
head(prediction)
```

```{r}
prediction_finale = data.frame("n0_joueur" = as.integer(row.names(prediction)), "prediction" = rep(0, length(prediction[,1])))
for (i in 1:length(prediction[,1])) {
  prediction_finale[i,2] = as.integer(which.max(prediction[i,]))
}
prediction_finale
```

```{r}
prediction_finale = cbind(prediction_finale, "reel" = 0)
```


```{r}
for (i in 1:length(prediction[,1])) {
  prediction_finale$reel[i] = test$Position[i]
}
prediction_finale
```

Calcul du taux d'erreur :

```{r}
testEgal <- function(var) {
  return(as.integer(var[2] == var[3]))
}
```

nombre d'erreurs :

```{r}
nReussite = apply(prediction_finale, 1, testEgal)
tauxReussiteVGLM = (sum(nReussite))/length(nReussite)
tauxReussiteVGLM
```

















